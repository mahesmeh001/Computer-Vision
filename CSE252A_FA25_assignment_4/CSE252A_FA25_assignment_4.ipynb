{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Jp_VhCl4te",
        "tags": []
      },
      "source": [
        "# CSE 252A Computer Vision I Fall 2025 - Assignment 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gISBijp3l4ti",
        "tags": []
      },
      "source": [
        "Instructor: Ben Ochoa\n",
        "\n",
        "Assigment due: Wed, Dec 3, 11:59 PM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gew4uj0rbEK"
      },
      "source": [
        "**Name:**\n",
        "\n",
        "**PID:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOXXS2dOl4tj",
        "tags": []
      },
      "source": [
        "## Instructions\n",
        "\n",
        "Please answer the questions below using Python in the attached Jupyter notebook and follow the guidelines below:\n",
        "\n",
        "- This assignment must be completed **individually**. For more details, please follow the Academic Integrity Policy and Collaboration Policy on [Canvas](https://canvas.ucsd.edu).\n",
        "\n",
        "- All the solutions must be written in this Jupyter notebook.\n",
        "\n",
        "- You may use basic algebra packages (e.g. `NumPy`, `SciPy`, etc) but you are not allowed to use the packages that directly solve the problems. Feel free to ask the instructor and the teaching assistants if you are unsure about the packages to use.\n",
        "\n",
        "- It is highly recommended that you begin working on this assignment early.\n",
        "\n",
        "- You must **submit 3 files: the Notebook, the PDF and the python file** (i.e. the `.ipynb`, the `.pdf` and the `.py` files) on Gradescope. **You must mark each problem on Gradescope in the pdf.**\n",
        "    - To convert the notebook to PDF, you can choose one way below:\n",
        "\n",
        "        - You may first export the notebook as HTML, and then print the web page as PDF\n",
        "\n",
        "            - e.g., in Chrome: File $\\rightarrow$ Save and Export Notebook as $\\rightarrow$ \"HTML\"; or in VScode: Open the Command Palette by pressing Ctrl+Shift+P (Windows/Linux) or Cmd+Shift+P (macOS), search for Jupyter: Export to HTML\n",
        "    \n",
        "            - Open the saved web page and right click $\\rightarrow$ Print... $\\rightarrow$ Choose \"Destination: Save as PDF\" and click \"Save\")\n",
        "\n",
        "        - If you have XeTex installed on your machine, you may directly export the notebook as PDF: e.g., in Chrome, File $\\rightarrow$ Save and Export Notebook as $\\rightarrow$ \"PDF\"\n",
        "\n",
        "        - You may use [nbconvert](https://nbconvert.readthedocs.io/en/latest/install.html) to convert the ipynb file to pdf using the following command\n",
        "        `jupyter nbconvert --allow-chromium-download --to webpdf filename.ipynb`\n",
        "\n",
        "    - To convert the notebook to python file, you can choose one way below:\n",
        "\n",
        "        - You may directly export the notebook as py: e.g., in Chrome, File $\\rightarrow$ Save and Export Notebook as $\\rightarrow$ \"Executable script\"; or in VScode: Open the Command Palette and search for Jupyter: Export to Python Script\n",
        "\n",
        "        - You may use [nbconvert](https://nbconvert.readthedocs.io/en/latest/install.html) to convert the ipynb file to python file using the following command\n",
        "    `jupyter nbconvert --to script filename.ipynb --output output_filename.py`\n",
        "\n",
        "- Please make sure the content in each cell (e.g. code, output images, printed results, etc.) are clearly visible and are not cut-out or partially cropped in your final PDF file.\n",
        "\n",
        "- While submitting on gradescope, please make sure to assign the relevant pages in your PDF submission for each problem.\n",
        "\n",
        "**Late Policy:** Assignments submitted late will receive a 15% grade reduction for each 12 hours late (i.e., 30% per day). Assignments will not be accepted 72 hours after the due date. If you require an extension (for personal reasons only) to a due date, you must request one as far in advance as possible. Extensions requested close to or after the due date will only be granted for clear emergencies or clearly unforeseeable circumstances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Setup\n",
        "\n",
        "Follow the directions on https://pytorch.org/get-started/locally/ to install Pytorch on your computer.\n",
        "\n",
        "Note: You will not need GPU support for this assignment so don't worry if you don't have one. Furthermore, installing with GPU support is often more difficult to configure so it is suggested that you install the CPU only version.\n",
        "\n",
        "Run the torch import statements below and print the version to verify your installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PyTorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Other libraries\n",
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from skimage import io\n",
        "from array import array\n",
        "\n",
        "print(f'Torch version {torch.__version__}')\n",
        "\n",
        "x = torch.rand(5,3)\n",
        "print(\"Print random tensor: \\n\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 1: Bayesian Classification [15 pts]\n",
        "\n",
        "In this problem, you will segment the image given below at the pixel level as foreground or background region by applying principles from Bayesian Decision Theory. You will be provided with feature vectors obtained from known foreground and background regions, along with corresponding feature vectors computed for every pixel for the test image. Your task is to use the training features to build probabilistic models for the two classes and then classify each pixel of the test image by evaluating the posterior probabilities.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"seg_image.png\" alt=\"seg_img\" width=\"300px\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Some Context About The Training Features**  \n",
        "\n",
        "Foreground and background regions in an image usually differ in texture. These differences can be interpreted as differences in their underlying frequency patterns. To capture this information, we use the Discrete Cosine Transform (DCT), a standard technique that represents an image block in terms of spatial patterns of varying frequencies (basis functions). If interested in learning more, see [CSE 166: Image Processing (Fall 2023)](https://cseweb.ucsd.edu/classes/fa23/cse166-a/) lecture [Basis vectors, basis images, and matrix-based transforms](https://cseweb.ucsd.edu/classes/fa23/cse166-a/lec10.pdf).\n",
        "\n",
        "For this problem, the image (taken as grayscale) is divided into overlapping 8Ã—8 blocks with a stride of 1, and the DCT is applied to each block. This results in 8x8, i.e., 64 DCT coefficient values. Now, from each block, we select the indices of the basis functions with the largest magnitudes (top 2 in this case), excluding the DC term that represents the average intensity. These indices will serve as the features of the local texture. All of this preprocessing has already been done for you, and you are given only the resulting feature vectors from the foreground and background regions, along with the feature vectors for every pixel in the test image.\n",
        "\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "1. Read the training data from the `TrainingSamples.pickle` file for foreground and background feature vectors.\n",
        "\n",
        "2. Compute the prior class probabilities using the training data (**3 points**).   \n",
        "   $P(\\text{bg}), P(\\text{fg})$\n",
        "\n",
        "3. Compute class-conditional probability distributions, and plot them (**4 points**).  \n",
        "\n",
        "   Assume feature independence across the dimensions of the feature vector. The joint probability of the features can be now written as:  \n",
        "   $P(x_1, x_2, \\ldots, x_K) = \\prod_{k=1}^{K} P(x_k)$   where $K$ represents the total number of features \n",
        "\n",
        "   For each class (foreground and background), compute a separate probability distribution for every feature value.  \n",
        "   Then plot all class feature combinations PDF, i.e.:\n",
        "\n",
        "   - $P(x_1 \\mid \\text{bg})$  \n",
        "   - $P(x_2 \\mid \\text{bg})$  \n",
        "   - $P(x_1 \\mid \\text{fg})$  \n",
        "   - $P(x_2 \\mid \\text{fg})$\n",
        "\n",
        "   **Note**: Each feature can take values between 1 to 64\n",
        "\n",
        "4. Read the test image and its feature vectors corresponding to each pixel value.\n",
        "\n",
        "5. Classify each pixel using the Maximum A Posteriori (MAP) classifier and generate the binary classification mask (0 for background and 1 for foreground) (**6 points**).  \n",
        "\n",
        "   **Note**: The generated mask is expected to be slightly noisy.\n",
        "\n",
        "6. Compare the predicted mask with the true mask and compute the classification error percentage (**2 points**).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.1: Read the Training Data and Compute Class Prior Probabilities [3 pts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load training data\n",
        "\n",
        "file_train_data = open('TrainingSamples.pkl', 'rb')\n",
        "train_data = pickle.load(file_train_data)\n",
        "file_train_data.close()\n",
        "bg_train_data = train_data['background']\n",
        "fg_train_data = train_data['foreground']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_class_priors(bg_data, fg_data):\n",
        "    \"\"\"Compute class prior probabilities for background and foreground classes.\n",
        "    \n",
        "    Args:\n",
        "        bg_data: NxD array of background training data, N is the number of samples, D is number of the feature dimensions.\n",
        "        fg_data: MXD array of Foreground training data, M is the number of samples, D is number of the feature dimensions.\n",
        "\n",
        "    Returns:\n",
        "        p_prior_bg: Prior probability of the background class.\n",
        "        prior_fg: Prior probability of the foreground class.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\" ==========\n",
        "    YOUR CODE HERE\n",
        "    ========== \"\"\"\n",
        "\n",
        "\n",
        "    return p_prior_bg, p_prior_fg\n",
        "\n",
        "\n",
        "p_prior_bg, p_prior_fg = compute_class_priors(bg_train_data, fg_train_data)\n",
        "print(f\"Prior Probability of Background Class: {p_prior_bg}\")\n",
        "print(f\"Prior Probability of Foreground Class: {p_prior_fg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.2: Compute Class Conditional Probability Distributions [4 pts]\n",
        "\n",
        "You may use the `plot_feature_pdf` function to plot the probability distributions for every feature dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CODE\n",
        "def plot_feature_pdf(p_bg_feature, p_fg_feature, feature_number):\n",
        "    \"\"\"\n",
        "    Plots the class-conditional probability distribution for a single feature for both classes.\n",
        "\n",
        "    Args:\n",
        "        p_bg_feature    : 1D array, P(x_k | bg) for this feature\n",
        "        p_fg_feature    : 1D array, P(x_k | fg) for this feature\n",
        "        feature_number  : integer, index of the feature being plotted starting from 1\n",
        "    \"\"\"\n",
        "    assert len(p_bg_feature) == len(p_fg_feature)\n",
        "\n",
        "    x_values = np.arange(1, len(p_fg_feature) + 1)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(x_values, p_bg_feature, label=\"P(x_{} | bg)\".format(feature_number))\n",
        "    plt.plot(x_values, p_fg_feature, label=\"P(x_{} | fg)\".format(feature_number))\n",
        "\n",
        "    plt.title(f\"Class Conditional PDFs for Feature {feature_number}\")\n",
        "    plt.xlabel(\"Feature value\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_feature_class_conditional_pdf(bg_feature_data, fg_feature_data):\n",
        "    \"\"\"\n",
        "    Computes the class-conditional probability distributions for a single feature.\n",
        "\n",
        "    Parameters:\n",
        "        bg_feature_data   : 1D background feature array of size N\n",
        "        fg_feature_data   : 1D background feature array of size M\n",
        "\n",
        "    Returns:\n",
        "        p_bg_feature  : P(x_k | bg), 1D array of size 64 \n",
        "        p_fg_feature  : P(x_k | fg), 1D array of size 64\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\" ==========\n",
        "    YOUR CODE HERE\n",
        "    ========== \"\"\"\n",
        "\n",
        "    return p_bg_feature, p_fg_feature\n",
        "\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE TO COMPUTE AND PLOT THE CLASS-CONDITIONAL PDFS\n",
        "========== \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.3: Classify using Maximum A Posteriori (MAP) Classifier [6 pts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the test data\n",
        "file_test_data = open('TestImageFeatures.pkl', 'rb')\n",
        "test_data = pickle.load(file_test_data)\n",
        "file_test_data.close()\n",
        "test_features = test_data['features']\n",
        "print(f\"Test data shape: {test_features.shape}\")\n",
        "\n",
        "def classify_map(test_features, p_bg_features, p_fg_features, prior_bg, prior_fg):\n",
        "    \"\"\"\n",
        "    Classify test samples using Maximum A Posteriori (MAP) rule.\n",
        "\n",
        "    Args:\n",
        "        test_features : M x N x D array of test features where M X N refers to image size and D refers to number of features\n",
        "        p_bg_features : D x 64 array containing background class conditional probability for features\n",
        "        p_fg_features : D x 64 array containing foreground class conditional probability for features\n",
        "        p_prior_bg    : Prior probability of background class\n",
        "        p_prior_fg    : Prior probability of foreground class\n",
        "    Returns:\n",
        "        prediction_mask   : M X N mask with value 0 for background and 1 for foreground\n",
        "    \"\"\"\n",
        "    \"\"\" ==========\n",
        "    YOUR CODE HERE\n",
        "    ========== \"\"\"\n",
        "    M, N, D = test_features.shape\n",
        "    prediction_mask = np.zeros((M, N), dtype=np.uint8)\n",
        "\n",
        "\n",
        "    return prediction_mask\n",
        "\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE TO COMPUTE AND DISPLAY THE PREDICTED MASK USING MAP CLASSIFIER\n",
        "========== \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1.4: Compute the percentage error of classification [2 pts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the binary ground truth mask\n",
        "ground_truth_mask = io.imread('seg_mask.png', as_gray=True)\n",
        "binary_mask = (ground_truth_mask > 128).astype(np.uint8)\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE TO COMPUTE AND PRINT CLASSIFICATION ERROR PERCENTAGE\n",
        "========== \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMy7Je11rbEL"
      },
      "source": [
        "## Problem 2: Machine Learning [30 pts]\n",
        "In this problem, you will implement several machine learning solutions for computer vision problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej1o7ElirbEM"
      },
      "source": [
        "### Part 2.1: Download MNIST data [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCKmfGHwrbEN"
      },
      "source": [
        "We will be using the Modified National Institute of Standards and Technology (MNIST) database for this problem. It is a well-known dataset consisting of 28x28 grayscale images of handwritten digits. The database consists of 60,000 train samples, and 10,000 test samples.\n",
        "\n",
        "To download it, visit the \"Resources\" tab on our Piazza page.\n",
        "\n",
        "We will be using the following four files:\n",
        "\n",
        "1. train-images.idx3-ubyte.gz: training set images\n",
        "2. train-labels.idx1-ubyte.gz: training set labels\n",
        "3. t10k-images.idx3-ubyte.gz: test set images\n",
        "4. t10k-labels.idx1-ubyte.gz: test set labels\n",
        "\n",
        "\n",
        "Download the files, and change the variable 'path' in the code below.\n",
        "Plot one random example image corresponding to each label from training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIBkHqCXrbEN"
      },
      "outputs": [],
      "source": [
        "# Change path as required\n",
        "path = \"mnist/\"\n",
        "\n",
        "def read(dataset = \"training\", datatype='images'):\n",
        "    \"\"\"\n",
        "    Python function for importing the MNIST data set.  It returns an iterator\n",
        "    of 2-tuples with the first element being the label and the second element\n",
        "    being a numpy.uint8 2D array of pixel data for the given image.\n",
        "    \"\"\"\n",
        "\n",
        "    if dataset == \"training\":\n",
        "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
        "    elif dataset == \"testing\":\n",
        "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
        "\n",
        "    # Load everything in some numpy arrays\n",
        "    with open(fname_lbl, 'rb') as flbl:\n",
        "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
        "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
        "\n",
        "    with open(fname_img, 'rb') as fimg:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
        "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
        "\n",
        "    if(datatype=='images'):\n",
        "        get_data = lambda idx: img[idx]\n",
        "    elif(datatype=='labels'):\n",
        "        get_data = lambda idx: lbl[idx]\n",
        "\n",
        "    # Create an iterator which returns each image in turn\n",
        "    for i in range(len(lbl)):\n",
        "        yield get_data(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oCy102drbEN",
        "outputId": "6baf76b9-04ef-48fd-b3f6-846b236152c7"
      },
      "outputs": [],
      "source": [
        "#Load the data\n",
        "\n",
        "#Train set\n",
        "trainData = np.array(list(read('training','images'))).astype(np.float32)\n",
        "trainLabels = np.array(list(read('training','labels')))\n",
        "\n",
        "#Test set\n",
        "testData = np.array(list(read('testing','images'))).astype(np.float32)\n",
        "testLabels=np.array(list(read('testing','labels')))\n",
        "\n",
        "# Understand the shapes\n",
        "print(trainData.shape, trainLabels.shape)\n",
        "print(testData.shape, testLabels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-rjlowwrbEN"
      },
      "source": [
        "Complete the `plot_sample_images()` to plot a 1x10 figure, where each column displays a sample image from a class. The following image gives an example:\n",
        "<!--- ![mnist](fig/mnist_example_plot.png) --->\n",
        "<!--- The previous results in export to pdf errors on some systems but the following does not --->\n",
        "<img src=\"fig/mnist_example_plot.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys2TFhI_rbEN"
      },
      "outputs": [],
      "source": [
        "def plot_sample_images(trainX, trainY):\n",
        "    \"\"\"\n",
        "    Function to plot a sample image for each category,\n",
        "    The result is a figure with 1x10 grid of images.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    \"\"\" ==========\n",
        "    YOUR CODE HERE\n",
        "    ========== \"\"\"\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4daOKbZ0rbEO",
        "outputId": "69e2bf77-a676-417c-f5e1-e05855ca9463"
      },
      "outputs": [],
      "source": [
        "# Plot the sample images as a 1x10 figure\n",
        "plot_sample_images(trainData, trainLabels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD68VE3pl4ts"
      },
      "source": [
        "### Problem 2.2: Recognizing hand-written digits with a KNN Classifier using sklearn [5 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ctL_Gwl4ts"
      },
      "source": [
        "In this part\n",
        "* complete the RandomClassifier class - given an input image, output a random class\n",
        "* complete the kNNClassifier class\n",
        "\n",
        "The Sklearn library provides an easy way to build and call different models. We will use `sklearn.neighbors.KNeighborsClassifier`. Check out the [documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWB9QzrrrbEO",
        "outputId": "eb01062d-4cc5-4fa0-cd2c-a0640dbb5339"
      },
      "outputs": [],
      "source": [
        "# DO NOT CHANGE\n",
        "# #Reshape the 2D Image matrix to 1D vector: (28, 28) -> (784,)\n",
        "#Shape of train_data: (N_train, 28, 28) -> (N_train, 784)\n",
        "trainData = trainData.reshape(trainData.shape[0], -1)\n",
        "\n",
        "#Shape of test_data: (N_test, 28, 28) -> (N_test, 784)\n",
        "testData = testData.reshape(testData.shape[0], -1)\n",
        "\n",
        "print(\"-----------------\\n\")\n",
        "print(\"After reshaping the data\")\n",
        "print(trainData.shape, trainLabels.shape)\n",
        "print(testData.shape, testLabels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDZ8BK3Ol4ts"
      },
      "outputs": [],
      "source": [
        "# DO NOT CHANGE\n",
        "#### Some helper functions are given below####\n",
        "\n",
        "def DataBatch(data, label, batchsize, shuffle=True):\n",
        "    \"\"\"\n",
        "    a generator for batches of data\n",
        "    yields data (batchsize, 28, 28) and labels (batchsize)\n",
        "    if shuffle is True, it will load batches in a random order\n",
        "    \"\"\"\n",
        "\n",
        "    n = data.shape[0]\n",
        "    if shuffle:\n",
        "        index = np.random.permutation(n)\n",
        "    else:\n",
        "        index = np.arange(n)\n",
        "    for i in range(int(np.ceil(n/batchsize))):\n",
        "        inds = index[i*batchsize : min(n,(i+1)*batchsize)]\n",
        "        yield data[inds], label[inds]\n",
        "\n",
        "def test(testData, testLabels, classifier):\n",
        "    # tests the accuracy of a classifier\n",
        "    batchsize=40\n",
        "    correct=0.\n",
        "    for data,label in DataBatch(testData,testLabels,batchsize,shuffle=False):\n",
        "        prediction = classifier(data)\n",
        "        correct += np.sum(prediction==label)\n",
        "    return correct/testData.shape[0]*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7luOWqyrbEO"
      },
      "outputs": [],
      "source": [
        "#Random Classifier\n",
        "class RandomClassifier():\n",
        "    \"\"\"\n",
        "    A random classifier.\n",
        "    Given an input image, it outputs a random class\n",
        "    \"\"\"\n",
        "    def __init__(self, classes=10):\n",
        "        self.classes=classes\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJXg7E08rbEO",
        "outputId": "16c57757-fbeb-4909-ca42-6a513c21ce06"
      },
      "outputs": [],
      "source": [
        "# TEST CODE: DO NOT CHANGE\n",
        "randomClassifierX = RandomClassifier()\n",
        "print ('Random classifier accuracy: %f'%test(testData, testLabels, randomClassifierX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6JnXh3jl4tt"
      },
      "outputs": [],
      "source": [
        "#Sklearn KNN Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "class kNNClassifier():\n",
        "    def __init__(self, k=5, algorithm='brute'):\n",
        "        \"\"\"\n",
        "        Initialize KNN model.\n",
        "\n",
        "        Inputs:\n",
        "        k: number of neighbors involved in voting\n",
        "        algorithm: Algorithm used to compute nearest neighbors\n",
        "        \"\"\"\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "        \n",
        "\n",
        "    def train(self, trainData, trainLabels):\n",
        "        \"\"\"\n",
        "        Train your model with image data and corresponding labels.\n",
        "\n",
        "        Inputs:\n",
        "        trainData: Training images (N_train,784)\n",
        "        trainLabels: Labels (N_train,)\n",
        "        \"\"\"\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Predict the trained model on test data.\n",
        "\n",
        "        Inputs:\n",
        "        x: Test images (N_test, 784)\n",
        "\n",
        "        Returns:\n",
        "        predicted labels (N_test,)\n",
        "        \"\"\"\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN3IyTafl4tu",
        "outputId": "01cc1a62-935e-40a0-a537-b9703aac80eb"
      },
      "outputs": [],
      "source": [
        "# Initialize the KNN classifier and train the model\n",
        "# Print the accuracy of the knn classifier (sklearn)\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt39SvrEl4tv"
      },
      "source": [
        "### Problem 2.3: Confusion Matrix [5 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jm0Zmzcl4tv"
      },
      "source": [
        "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
        "\n",
        "Here you will implement a function that computes the confusion matrix for a classifier. The matrix (M) is $n \\times n$ where $n$ is the number of classes. Entry `M[i,j]` represents the counts of images from class `i` that was classified as class `j`.\n",
        "\n",
        "Your task is to:\n",
        "* complete the `Confusion()`\n",
        "* plot the results for `randomClassifier` and discuss the results\n",
        "* plot the results for `kNNClassifier`\n",
        "\n",
        "The following image shows a visual example of a confusion matrix:\n",
        "<p>\n",
        "    <img src=\"fig/eg_confusion.png\" width=\"300px\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP43z3lOl4tv"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def Confusion(testData, testLabels, classifier):\n",
        "    '''\n",
        "    Compute the confusion matrix and accuracy for the classifier.\n",
        "    Inputs:\n",
        "        testData: Test images (N_test, 784)\n",
        "        testLabels: Test labels (N_test,)\n",
        "        classifier: The model to predict the labels\n",
        "    Returns:\n",
        "        M: The confusion matrix\n",
        "        acc: The accuracy of the model\n",
        "    '''\n",
        "    batchsize = 40\n",
        "    M = np.zeros((10,10))\n",
        "    acc = 0\n",
        "\n",
        "    for data,label in tqdm(DataBatch(testData,testLabels,batchsize,shuffle=False),total=len(testData)//batchsize):\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "\n",
        "def VisualizeConfusion(M):\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.imshow(M)\n",
        "    plt.show()\n",
        "    print(np.round(M,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lXrWBS6rbEP",
        "outputId": "c6b2c8e9-3a90-40fc-f1bf-22e9ef5879b7"
      },
      "outputs": [],
      "source": [
        "# Print the accuracy and plot the confusion matrix for the random classifier on the test set\n",
        "M_r, acc_r = Confusion(testData, testLabels, randomClassifierX)\n",
        "print(f\"Accuracy of random classifier {acc_r*100}%\")\n",
        "\n",
        "VisualizeConfusion(M_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8OmmbRzrbEP"
      },
      "source": [
        "#### **Exercise**: Justify the accuracy & values of the confusion matrix of the random classifier below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kov5RkfGrbEP"
      },
      "source": [
        "Your answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "YWZFcKjal4tw",
        "outputId": "780e38b6-bbfc-40d5-ee96-ee6a75561415"
      },
      "outputs": [],
      "source": [
        "# Print the accuracy and plot the confusion matrix for the KNN classifier on the test set\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HnFGSRFl4tw"
      },
      "source": [
        "### Problem 2.4: K-Nearest Neighbors (KNN) [8 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l8Vxkoil4tw"
      },
      "source": [
        "For this problem, you will complete a simple kNN classifer ***without Sklearn***. The distance metric is ***Euclidean distance (L2 norm)*** in pixel space. You may use the **np.linalg.norm** function to compute distance. $k$ refers to the number of neighbors involved in voting on the class. Use $k$ value to be equal to 3.\n",
        "\n",
        "**NOTE:** \n",
        "* For debugging the code, use only the first 250 train samples. You can expect to get 74.02% accuracy while using the first 250 training samples.\n",
        "* For the final submission, you are encouraged to use the entire training set (60000 samples). However, it may take some time (~ 30 mins). If you get the expected accuracy for 250 train samples, this should just be a 1 time run.\n",
        "* In case it takes too long, you may consider the first 30000 training samples.\n",
        "* Do not reduce the size of the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-D-znLZl4tx",
        "outputId": "a478a777-7cb6-4077-ddc0-16e9914c129d"
      },
      "outputs": [],
      "source": [
        "class kNNClassifierManual():\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def train(self, trainData, trainLabels):\n",
        "        self.X_train = trainData\n",
        "        self.y_train = trainLabels\n",
        "\n",
        "    def __call__(self, X):\n",
        "        \"\"\"\n",
        "        Predict the labels for the input data using KNN method.\n",
        "\n",
        "        Inputs:\n",
        "        X: Test images (N_test,784)\n",
        "\n",
        "        Returns:\n",
        "        predicted labels (N_test,)\n",
        "        \"\"\"\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "        \n",
        "# test your classifier with only the first 250 training examples \n",
        "# (use this while debugging)\n",
        "# note you must get 74.02% accuracy\n",
        "knnClassiferX = kNNClassifierManual()\n",
        "knnClassiferX.train(trainData[:250], trainLabels[:250])\n",
        "print(f'KNN classifier accuracy: {test(testData, testLabels, knnClassiferX)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6VGe2CBrbEP",
        "outputId": "c30879b4-1140-4d7d-f65c-5d14b97ead19"
      },
      "outputs": [],
      "source": [
        "# Initialize the KNN classifier and assign the train data\n",
        "# Print the accuracy and plot the confusion matrix for the knn classifier (manual) on the test set\n",
        "# (This may take a max of 30 min)\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In case it takes too long to run the previous cell, you can use the following code. \n",
        "# You DO NOT HAVE TO RUN THIS CELL if the previous cell runs successfully.\n",
        "# Initialize the KNN classifier and assign the train data\n",
        "# Print the accuracy and plot the confusion matrix for the knn classifier (manual) on the test set\n",
        "# Using the first 30000 training examples\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukVkxBBKrbEQ"
      },
      "source": [
        "#### **Exercise**: What number, other than itself, is the number '2' predicted to be? Also calculate the percentage of error for predicting the number 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dhdErGWrbEQ"
      },
      "source": [
        "Your answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZQQIiKPnRQF"
      },
      "source": [
        "### Problem 2.5: Principal Component Analysis (PCA) K-Nearest Neighbors (KNN) [9 pts]\n",
        "Here you will implement a simple KNN classifer in PCA space (for k=5 and 30 principal components).\n",
        "You must implement PCA yourself using singular value decomposition (SVD) **(you may not use sklearn.decomposition.PCA or any other package that directly implements PCA transformations)**\n",
        "\n",
        "You may use your previous implementation of the KNN classifier in this part or you may use `KNeighborsClassifier` from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e06z90dxm7Af",
        "outputId": "a20076bf-52f0-4843-aecb-9bbc40f32eb8"
      },
      "outputs": [],
      "source": [
        "class PCAKNNClassifer():\n",
        "    def __init__(self, components=30, k=5):\n",
        "        \"\"\"\n",
        "        Initialize PCA kNN classifier\n",
        "\n",
        "        Inputs:\n",
        "        components: number of principal components\n",
        "        k: number of neighbors involved in voting\n",
        "        \"\"\"\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "\n",
        "    def train(self, trainData, trainLabels):\n",
        "        \"\"\"\n",
        "        Train your model with image data and corresponding labels.\n",
        "\n",
        "        Inputs:\n",
        "        trainData: Training images (N_train, 784)\n",
        "        trainLabels: Labels (N_train,)\n",
        "        \"\"\"\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        Predict the trained model on test data.\n",
        "\n",
        "        Inputs:\n",
        "        x: Test images (N_test, 784)\n",
        "\n",
        "        Returns:\n",
        "        predicted labels (N_test,)\n",
        "        \"\"\"\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "\n",
        "# test your classifier with only the first 250 training examples\n",
        "# (use this while debugging)\n",
        "# note you must get 75.8% accuracy\n",
        "pcaknnClassiferX = PCAKNNClassifer()\n",
        "pcaknnClassiferX.train(trainData[:250], trainLabels[:250])\n",
        "print ('PCA KNN classifier accuracy: %f'%test(testData, testLabels, pcaknnClassiferX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "eSbD_cdeoOY5",
        "outputId": "b2680f2a-d2cd-40f0-de5c-670b0511deef"
      },
      "outputs": [],
      "source": [
        "# Initialize the PCA KNN classifier and assign the training data\n",
        "# Print the accuracy and plot the confusion matrix for the PCA KNN classifier on the test set\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuQfPRnEpM9c"
      },
      "source": [
        "#### Exercise:  Is the testing time for PCA KNN classifier more or less than that for KNN classifier? Comment on why it differs, if it does.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bupXFemSrbEV"
      },
      "source": [
        "Your answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8ol8VCDpV8Q"
      },
      "source": [
        "## Problem 3: Deep learning [28 pts]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNHTCDtSrbEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.optim as optim\n",
        "\n",
        "from scipy.stats import truncnorm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wu-weDbqEAY"
      },
      "source": [
        "### Problem 3.1:  Training with PyTorch [8 pts]\n",
        "\n",
        "Below is some helper code to train your deep networks.\n",
        "\n",
        "Complete the `train_net()` for DNN below. You must code the training operations in this function.\n",
        "For a batch of data you have to\n",
        "* initialize the gradients\n",
        "* forward propagate the data\n",
        "* compute error\n",
        "* do back propagation\n",
        "* finally update the parameters.\n",
        "\n",
        "**NOTE:**\n",
        "* You would have to choose an appropriate ***loss function*** and ***optimizer*** from PyTorch for this problem.\n",
        "* Set the default learning rate as 3e-4, epoch as 15 and batch size as 40\n",
        "* Append ***each batch*** loss in the list `self.losses`. The size of self.losses after training must be `epochs*number_batches`. This will be used in the later section.\n",
        "\n",
        "This function will be used in the following questions with different networks.\n",
        "You may look at [this toturial](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky0FksEwqDta"
      },
      "outputs": [],
      "source": [
        "# Base class for your deep neural networks\n",
        "\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self, lr = 3e-4):\n",
        "        super(DNN, self).__init__()\n",
        "        self.lr = lr\n",
        "        self.losses = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError # You do not need need to implement anything here\n",
        "\n",
        "    def train_net(self, X_train, y_train, epochs=15, batchSize=40):\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "        \n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.eval()  # set network in evaluation mode\n",
        "        inputs = torch.tensor(x, dtype=torch.float32)\n",
        "        prediction = self.forward(inputs)\n",
        "        return np.argmax(prediction.data.cpu().numpy(), 1)\n",
        "\n",
        "    def plot_losses(self):\n",
        "        plt.plot(self.losses)\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(f'Training loss over {len(self.losses)} iterations with learning rate {self.lr}')\n",
        "        plt.show()\n",
        "\n",
        "# Helper function to intialize weight variables\n",
        "def weight_variable(shape):\n",
        "    initial = torch.Tensor(truncnorm.rvs(-1/0.01, 1/0.01, scale=0.01, size=shape))\n",
        "    return nn.Parameter(initial, requires_grad=True)\n",
        "\n",
        "# helper function to get bias variables\n",
        "def bias_variable(shape):\n",
        "    initial = torch.Tensor(np.ones(shape)*0.1)\n",
        "    return nn.Parameter(initial, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HYVuzbtosJo"
      },
      "outputs": [],
      "source": [
        "# Example linear classifier - input connected to output\n",
        "# You can use this as an example to see how to extend the DNN class\n",
        "\n",
        "class LinearClassifier(DNN):\n",
        "    def __init__(self, lr = 3e-4, in_features=28*28, classes=10):\n",
        "        super(LinearClassifier, self).__init__(lr)\n",
        "        # in_features=28*28\n",
        "        self.weight1 = weight_variable((classes, in_features))\n",
        "        self.bias1 = bias_variable((classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # linear operation\n",
        "        y_pred = torch.addmm(self.bias1, x.view(list(x.size())[0], -1), self.weight1.t())\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCMXO8MmrbEV",
        "outputId": "abff78ff-383e-4aca-b6d7-a7f36566bf5f"
      },
      "outputs": [],
      "source": [
        "# Re-loading the train data\n",
        "trainData = np.array(list(read('training','images')))\n",
        "trainLabels = np.int32(np.array(list(read('training','labels'))))\n",
        "\n",
        "# Add a channel dimension to the data - Since these are grayscale images, the channel dimension is 1\n",
        "# Normalize\n",
        "# Reshape the data to (N, C, H, W) format\n",
        "trainData = np.float32(np.expand_dims(trainData, -1))/255\n",
        "trainData = trainData.transpose((0,3,1,2))\n",
        "\n",
        "# Re-loading the train data\n",
        "testData = np.array(list(read('testing','images')))\n",
        "testLabels = np.int32(np.array(list(read('testing','labels'))))\n",
        "\n",
        "# Add a channel dimension to the data - Since these are grayscale images, the channel dimension is 1\n",
        "# Normalize\n",
        "# Reshape the data to (N, C, H, W) format\n",
        "testData=np.float32(np.expand_dims(testData,-1))/255\n",
        "testData=testData.transpose((0,3,1,2))\n",
        "\n",
        "\n",
        "print(\"-----------------\\n\")\n",
        "print(\"After reshaping the data\")\n",
        "print(trainData.shape, trainLabels.shape)\n",
        "print(testData.shape, testLabels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGaoAMjtrbEV",
        "outputId": "02b1c167-cf26-44ec-a82e-bc2b0cd7a644"
      },
      "outputs": [],
      "source": [
        "# Initialize the Linear classifier and train the model\n",
        "# Print the accuracy and plot the confusion matrix for the linear classifier on the test set\n",
        "# Note - You must get ~92% accuracy for 15 epochs and batch size 40\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNzcCiLr0AU8"
      },
      "source": [
        "### Problem 3.2: Single Layer Perceptron [3 pts]\n",
        "\n",
        "The simple linear classifier implemented in the cell already performs quite well. Plot the ***weights*** of the fully connected layer corresponding to each output class as images ***(not the biases)***. (Plot a 1x10 figure, where each column corresponds to the filter weights of a class, just like as you did in Problem 2.1)\n",
        "\n",
        "Comment on what the weights look like, and why you think this is the result.\n",
        "\n",
        "**NOTE:** To obtain the weights, you can access the ***linear layer*** in the model. For example you can obtain the weights in `weight1` by accessing `weight1.data`. ***Normalize*** and ***reshape*** the weights to make sense of them. You may explore different ***cmaps*** like ***plasma***, ***inferno***, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "Q8S3dYZgzzT_",
        "outputId": "77893fac-c764-4ca3-9151-07d171507dc1"
      },
      "outputs": [],
      "source": [
        "# Plot filter weights corresponding to each class.\n",
        "# Plot a 1x10 figure where each column corresponds to the filter weights of a class\n",
        "# Normalize the weights to be between 0 and 1\n",
        "# Reshape the weights\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmQUOBNg0PkW"
      },
      "source": [
        "#### Exercise: Comment on what the weights look like and your reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Your answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJBWgsBE0S7K"
      },
      "source": [
        "### Part 3.3: Multi Layer Perceptron (MLP) [5 pts]\n",
        "Here you will implement an MLP. The MLP must consist of 2 layers (matrix multiplication and bias offset) that map to the following feature dimensions:\n",
        "\n",
        "* Hidden layer: 150 dimensional feature\n",
        "* Output layer: 10 dimensional feature (10 classes)\n",
        "\n",
        "* The hidden layer must be followed with a ReLU nonlinearity. The output layer must not have a nonlinearity applied as we desire the raw logits output. You may use `F.relu` for this.\n",
        "\n",
        "Display the confusion matrix and accuracy after training. Note: You must get ~97 % accuracy for 15 epochs and batch size 40.\n",
        "\n",
        "Plot the filter weights of\n",
        "* layer 1 corresponding to the mapping from the inputs to the first 10 hidden layer outputs (out of 150).\n",
        "* layer 2\n",
        "\n",
        "Do the weights look similar to the weights plotted in the previous problem? Why or why not?\n",
        "\n",
        "**Note**: You MUST initialize the weights with the helper functions given above, and then perform the described operations in `forward()`. You are NOT allowed to simply just use `nn.Linear` for example in this assignment. While in practice you would simply use these modules, we want you to implement the operations that they perform.\n",
        "\n",
        "It is expected that the training model would take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss2lUgpL0JRh"
      },
      "outputs": [],
      "source": [
        "class MLPClassifer(DNN):\n",
        "    def __init__(self, in_features=28*28, classes=10, hidden=100):\n",
        "        \"\"\"\n",
        "        Initialize weight and bias variables\n",
        "        \"\"\"\n",
        "        super(MLPClassifer, self).__init__()\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A57itKoerbEW",
        "outputId": "43880694-fa45-4e41-9841-b726737d7b81"
      },
      "outputs": [],
      "source": [
        "# Initialize the MLP classifier and train the model\n",
        "# Print the accuracy and plot the confusion matrix for the MLP classifier on the test set\n",
        "# Note - You must get ~97 % accuracy for 15 epochs and batch size 40.\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L49CjpjnrbEW"
      },
      "source": [
        "#### Plot the resulting layer 1 filter weights (1x10 figure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "FLD0yjHH0bVU",
        "outputId": "279908b4-30c5-4e2a-c9a8-7bd2165d2f2e"
      },
      "outputs": [],
      "source": [
        "# Plot the resulting layer 1 filter weights as a 1x10 figure\n",
        "# You may reuse the earlier code\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WITuHJ2zrbEW"
      },
      "source": [
        "#### Plot the resulting layer 2 filter weights (1x10 figure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqJM7W0WrbEW",
        "outputId": "4773c309-7f78-4bea-f23e-06ff3d3f1825"
      },
      "outputs": [],
      "source": [
        "# Plot the resulting layer 2 filter weights as a 1x10 figure\n",
        "# You may reuse the earlier code\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pCLEVJ_1F66"
      },
      "source": [
        "#### Exercise: Do the weights look similar to the weights plotted in the previous problem? Why or why not?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssidhu6frbEW"
      },
      "source": [
        "Your answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBC6s9qQ1KKj"
      },
      "source": [
        "### Problem 3.4: Convolutional Neural Network (CNN) [8 pts]\n",
        "\n",
        "Here you will implement a CNN with the following architecture:\n",
        "\n",
        "* Convolutional layer with 5x5 kernels, stride of 2, padding of 2, and 10 output channels, with bias\n",
        "* Convolutional layer with 5x5 kernels, stride of 2, padding of 2, and 15 output channels, with bias\n",
        "* Linear layer with 32 hidden units, with bias\n",
        "* Linear layer with 10 hidden units (number of classes), with bias\n",
        "* ReLU activation after each, except for the output layer.\n",
        "\n",
        "So, 2 convolutional layers, followed by 1 fully connected hidden layer into the output layer.\n",
        "\n",
        "**Note**: You MUST initialize the weights with the helper functions given above, and then perform the described operations in the `forward()` function. You are **NOT allowed** to simply just use `nn.Linear`, `nn.Conv2d` or `nn.Sequential` for example in this assignment. While in practice you could simply use these modules, we want you to implement the operations that they perform. You may use `F.conv2d`, `F.relu` and `torch.addmm` functions.\n",
        "\n",
        "Display the confusion matrix and accuracy after training. You must get ~98% accuracy for 15 epochs and batch size 40."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OhmF0NM1Clj"
      },
      "outputs": [],
      "source": [
        "# Helper function to perform convolution\n",
        "def conv2d(x, W, stride, padding, bias):\n",
        "    # x: input\n",
        "    # W: weights (out, in, kH, kW)\n",
        "    # stride: stride\n",
        "    # padding: padding\n",
        "    # bias: bias (out)\n",
        "    return F.conv2d(x, W, stride=stride, padding=padding, bias=bias)\n",
        "\n",
        "# Convolutional Neural Network\n",
        "class CNNClassifer(DNN):\n",
        "    def __init__(self, input_features=28*28, classes=10):\n",
        "        super(CNNClassifer, self).__init__()\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" ==========\n",
        "        YOUR CODE HERE\n",
        "        ========== \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG9fddI6rbEW",
        "outputId": "4c366431-1256-4817-df20-aa3b172bb264"
      },
      "outputs": [],
      "source": [
        "# Initialize the CNN Classifier and train the model\n",
        "# Print the accuracy and plot the confusion matrix for the test data\n",
        "# Note - You must get ~98% accuracy for 15 epochs and batch size 40.\n",
        "\n",
        "\"\"\" ==========\n",
        "YOUR CODE HERE\n",
        "========== \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHx9gSiK1xVp"
      },
      "source": [
        "* Note that the MLP/ConvNet approaches lead to an accuracy a little higher than the K-NN approach.\n",
        "* In general, Neural net approaches lead to significant increase in accuracy, but in this case since the problem is not too hard, the increase in accuracy is not very high.\n",
        "* However, this is still quite significant considering the fact that the ConvNets we've used are relatively simple while the accuracy achieved using K-NN is with a search over 60,000 training images for every test image.\n",
        "* You can look at the performance of various machine learning methods on this problem at https://yann.lecun.org/exdb/mnist/\n",
        "* PyTorch has a bunch of great tutorials online. You can learn more about neural networks and pytorch through the tutorials on their site for example: https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
        "* You can play with a demo of neural network created by Daniel Smilkov and Shan Carter at https://playground.tensorflow.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pffnHrTKrbEW"
      },
      "source": [
        "### Part 3.5: Hyperparameter Experiment (4 pts)\n",
        "\n",
        "Hyperparameters are parameters which are used to control the training/optimization process. These hyperparameters, unlike the parameters within the model, are set usually at the beginning of training and are not learned through the optimization process.\n",
        "\n",
        "Learning rate is an example of a hyperparameter. You may re-use the `LinearClassifier()` class we defined in Problem 2.1. Train the model with the following settings for learning rate and call the `plot_losses()` function to show the loss over the iterations.\n",
        "\n",
        "Train for just 5 epochs with three different settings of learning rate:\n",
        "\n",
        "* Learning rate = 0.2\n",
        "* Learning rate = 0.002\n",
        "* Learning rate = 0.00002\n",
        "\n",
        "Comment below on the results of the experiment. What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX6TXJMirbEW",
        "outputId": "9562cdf9-f959-4d94-b5aa-c54fe0376fba"
      },
      "outputs": [],
      "source": [
        "# Train and plot with learning rate = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mELa-RHorbEW",
        "outputId": "98133633-b500-47a5-bb9d-d7e6a579d258"
      },
      "outputs": [],
      "source": [
        "# Train and plot with learning rate = 0.002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TadNNg43rbEW",
        "outputId": "0626e679-f3f7-496c-f9f4-a2a6ff19d93b"
      },
      "outputs": [],
      "source": [
        "# Train and plot with learning rate = 0.00002"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWcsfCJlrbEX"
      },
      "source": [
        "#### Exercise: Comment below on the results of the experiment. What do you see? (comment on the convergence speed, whether the steps are noisy, is the training complete?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGyvdEm7rbEX"
      },
      "source": [
        "Your answer:"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [
        "jt39SvrEl4tv",
        "0HnFGSRFl4tw",
        "jZQQIiKPnRQF",
        "iuQfPRnEpM9c",
        "aYf3GsdmpfvS",
        "6Wu-weDbqEAY",
        "mNzcCiLr0AU8",
        "zmQUOBNg0PkW",
        "gJBWgsBE0S7K",
        "7pCLEVJ_1F66",
        "tBC6s9qQ1KKj"
      ],
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "nerf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "123px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
